{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25846bb0-a465-4aec-90d2-849797751858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Please install OpenAI SDK first: `pip3 install openai`\n",
    "# !pip install -U openai\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datasets\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "def generate_response(user_prompt, API_KEY):\n",
    "    client = OpenAI(api_key=API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "    system_prompt = \"\"\"\n",
    "    The user will provide some social media post text, parse and output in JSON format, \"1\" if the post is toxic, and \"0\" if not toxic. \n",
    "    \n",
    "    EXAMPLE INPUT: \n",
    "    COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
    "    \n",
    "    EXAMPLE JSON OUTPUT:\n",
    "    {\n",
    "        \"cyberbullying\": 1\n",
    "    }\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        response_format={'type': 'json_object'},\n",
    "        stream=False\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "def generate_response_multiclass(user_prompt, API_KEY):\n",
    "    client = OpenAI(api_key=API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "    system_prompt = \"\"\"\n",
    "    The user will provide some social media post text, parse and output in JSON format, multi-label classify the post for each of the following categories: toxic, severe toxic, obscene, threat, insult, identity hate. \n",
    "    \n",
    "    EXAMPLE INPUT: \n",
    "    COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
    "    \n",
    "    EXAMPLE JSON OUTPUT:\n",
    "    {\n",
    "        \"toxic\": 1,\n",
    "        \"severe toxic\": 1,\n",
    "        \"obscene\": 1,\n",
    "        \"threat\": 0,\n",
    "        \"insult\": 1,\n",
    "        \"identity hate\": 0\n",
    "    }\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        response_format={'type': 'json_object'},\n",
    "        stream=False\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "def call_all(list_of_comments, dpsk_func, API_KEY):\n",
    "    \"\"\"Function to run the deepseek call on all the text data and output a JSON file\"\"\"\n",
    "    json_outputs = []\n",
    "    for comment in tqdm(list_of_comments, desc=\"Processing comments\", unit=\"comment\"):\n",
    "        try:\n",
    "            result = dpsk_func(comment, API_KEY)\n",
    "            json_outputs.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error on comment: {comment[:30]}... -> {e}\")\n",
    "            json_outputs.append({\"error\": str(e)})\n",
    "    return json_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b80e7d-15a0-4c8f-84b6-9aeea8f8fd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'cyberbullying'],\n",
      "        num_rows: 159571\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'cyberbullying'],\n",
      "        num_rows: 63978\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# df = pd.read_excel(\"train.xlsx\")\n",
    "\n",
    "# # Clean and prepare data\n",
    "# df = df.dropna(subset=[\"comment_text\", \"cyberbullying\"])\n",
    "# df[\"comment_text\"] = df[\"comment_text\"].astype(str)\n",
    "# df[\"cyberbullying\"] = df[\"cyberbullying\"].astype(int)\n",
    "\n",
    "# def is_valid_text(t):\n",
    "#     return isinstance(t, str) and len(t.strip()) > 0\n",
    "\n",
    "# df = df[df[\"comment_text\"].apply(is_valid_text)]\n",
    "# comments = df[\"comment_text\"].tolist()\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.load_from_disk(\"processed_dataset\")\n",
    "print(dataset)\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d7af53b-5bfc-422a-b59f-4a3eed45a51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'cyberbullying'],\n",
      "    num_rows: 500\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# filter rows which are classified as cyberbullying\n",
    "cyb_testdata = test_data.filter(lambda example: example['cyberbullying'] == 1)\n",
    "# print(cyb_testdata[:5])\n",
    "# filter rows which are classified as not cyberbullying\n",
    "no_cyb_testdata = test_data.filter(lambda example: example['cyberbullying'] == 0)\n",
    "# print(no_cyb_testdata[:5])\n",
    "\n",
    "# randomly select 250 rows from cyb_testdata and 250 rows from no_cyb_testdata\n",
    "cyb_testdata = cyb_testdata.shuffle(seed=100).select(range(250))\n",
    "no_cyb_testdata = no_cyb_testdata.shuffle(seed=100).select(range(250))\n",
    "# print(cyb_testdata[:5])\n",
    "# print(no_cyb_testdata[:5])\n",
    "assert cyb_testdata.features.type == no_cyb_testdata.features.type\n",
    "sub_testdata = datasets.concatenate_datasets([cyb_testdata, no_cyb_testdata])\n",
    "print(sub_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf22ee3-39ec-4622-8ac5-0ead8ce31349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "# convert test_data to a list\n",
    "test_list = sub_testdata['comment_text']\n",
    "print(len(test_list[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184379c-1e4d-4580-b903-75d74533cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"API KEY\"\n",
    "# binary label\n",
    "json_outputs = call_all(test_list, generate_response, API_KEY)\n",
    "json_array = json.dumps(json_outputs, indent=4)\n",
    "with open('cyberbullying.json', 'w') as file:\n",
    "    file.write(json_array)\n",
    "    \n",
    "# multi-label\n",
    "json_outputs = call_all(test_list, generate_response_multiclass, API_KEY)\n",
    "json_array = json.dumps(json_outputs, indent=4)\n",
    "with open('cyberbullying_multi.json', 'w') as file:\n",
    "    file.write(json_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff2e8c-5df8-4913-992d-302dcab250d3",
   "metadata": {},
   "source": [
    "# Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d201af8e-4402-4bb7-b9cf-25a7fc132127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'cyberbullying'],\n",
      "    num_rows: 500\n",
      "})\n",
      "Dataset({\n",
      "    features: ['cyberbullying'],\n",
      "    num_rows: 500\n",
      "})\n",
      "Dataset({\n",
      "    features: ['toxic', 'severe toxic', 'obscene', 'threat', 'insult', 'identity hate'],\n",
      "    num_rows: 500\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# first, join the json results with the existing data\n",
    "sub_test = datasets.load_from_disk(\"subset_test\")\n",
    "print(sub_test)\n",
    "cyb = datasets.load_dataset(\"json\", data_files=\"cyberbullying_binary.json\")['train']\n",
    "cyb_multi = datasets.load_dataset(\"json\", data_files=\"cyberbullying_multi.json\")['train']\n",
    "print(cyb)\n",
    "print(cyb_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb1ab66a-8660-414e-bb97-91458cfce235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8460\n",
      "F1 Score: 0.8459\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, hamming_loss\n",
    "import numpy as np\n",
    "# Extract predictions and true labels\n",
    "y_pred = cyb[\"cyberbullying\"]\n",
    "y_true = sub_test[\"cyberbullying\"]\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Evaluate F1 score (micro or macro depending on your dataset)\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")  # Use since classes are equally distributed in the dataset, micro or macro doesn't matter\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "484bfae0-b8a5-44b8-9d9c-07e5478ba2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 4839.92 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 7067.61 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset Accuracy: 0.4940\n",
      "Hamming Loss: 0.1403\n",
      "F1 Score (Micro): 0.7029\n",
      "F1 Score (Macro): 0.5761\n",
      "F1 Score (each class): [0.85080645 0.28571429 0.75432526 0.34482759 0.70621469 0.51485149]\n"
     ]
    }
   ],
   "source": [
    "# Define your target multi-label columns\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "pred_cols = ['toxic', 'severe toxic', 'obscene', 'threat', 'insult', 'identity hate']\n",
    "# Map the references dataset to get multi-label vectors\n",
    "sub_test = sub_test.map(lambda x: {'label': [x[col] for col in label_cols]})\n",
    "# Map the predictions dataset similarly\n",
    "cyb_multi = cyb_multi.map(lambda x: {'pred': [x[col] for col in pred_cols]})\n",
    "\n",
    "# Extract predictions and true labels\n",
    "y_pred = np.array(cyb_multi[\"pred\"])\n",
    "y_true = np.array(sub_test[\"label\"])\n",
    "\n",
    "# Compute metrics\n",
    "subset_acc = accuracy_score(y_true, y_pred)\n",
    "f1_micro = f1_score(y_true, y_pred, average=\"micro\")\n",
    "f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "f1_none = f1_score(y_true, y_pred, average=None)\n",
    "# Hamming Loss, The Hamming loss is the fraction of labels that are incorrectly predicted.\n",
    "hamming = hamming_loss(y_true, y_pred)\n",
    "\n",
    "print(f\"Subset Accuracy: {subset_acc:.4f}\")\n",
    "print(f\"Hamming Loss: {hamming:.4f}\")\n",
    "print(f\"F1 Score (Micro): {f1_micro:.4f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1 Score (each class): {f1_none}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58002f0-18e4-42c9-b87e-56efa971e773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
