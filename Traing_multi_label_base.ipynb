{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85db4c5-1881-4027-85a8-ae420771f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import accelerate\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b24ea0-b580-4549-8a14-5cdc823d1d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0000997932d777bf',\n",
       " 'comment_text': \"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
       " 'toxic': 0,\n",
       " 'severe_toxic': 0,\n",
       " 'obscene': 0,\n",
       " 'threat': 0,\n",
       " 'insult': 0,\n",
       " 'identity_hate': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_file(r\"processed_dataset\\train\\data-00000-of-00001.arrow\")\n",
    "train_dataset = train_dataset.remove_columns('cyberbullying')\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102b54e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0001ea8717f6de06',\n",
       " 'comment_text': 'Thank you for understanding. I think very highly of you and would not revert without discussion.',\n",
       " 'toxic': 0,\n",
       " 'severe_toxic': 0,\n",
       " 'obscene': 0,\n",
       " 'threat': 0,\n",
       " 'insult': 0,\n",
       " 'identity_hate': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset.from_file(r\"processed_dataset\\test\\data-00000-of-00001.arrow\")\n",
    "test_dataset = test_dataset.remove_columns('cyberbullying')\n",
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace9188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'toxic':0, 'severe_toxic':1, 'obscene':2, 'threat':3, 'insult':4, 'identity_hate':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b039d510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "print(set(train_dataset['toxic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b37ff8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 159571/159571 [00:20<00:00, 7734.13 examples/s]\n",
      "Map: 100%|██████████| 63978/63978 [00:07<00:00, 8181.40 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '0000997932d777bf',\n",
       " 'comment_text': \"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
       " 'labels': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating a labels column for multi-label classification (instead of multi-class classification)\n",
    "\"\"\"\n",
    "def create_multi_label(example):\n",
    "    return {\"labels\": [np.float32(example[label]) for label in label_map.keys()]}\n",
    "\n",
    "train_dataset = train_dataset.map(create_multi_label).remove_columns(list(label_map.keys()))\n",
    "test_dataset = test_dataset.map(create_multi_label).remove_columns(list(label_map.keys()))\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bfa32f7-d4bf-44e7-9fe0-c448f77dd184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 159571/159571 [00:23<00:00, 6858.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 159571\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"  # Or any other BERT variant\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"comment_text\"], truncation=True, padding=\"max_length\", max_length=128\n",
    "    )\n",
    "    return tokenized_inputs\n",
    "\n",
    "def cast_labels_to_float32(example):\n",
    "    example[\"labels\"] = [np.float32(label) for label in example[\"labels\"]]\n",
    "    return example\n",
    "# Apply the preprocessing function\n",
    "tokenized_train_datasets = train_dataset.map(preprocess_function, batched=True)\n",
    "#tokenized_train_datasets = tokenized_train_datasets.map(cast_labels_to_float32, batched=True)\n",
    "tokenized_train_datasets = tokenized_train_datasets.remove_columns([\"id\", \"comment_text\",])\n",
    "\n",
    "#tokenized_train_datasets.set_format(\"torch\")\n",
    "\n",
    "print(tokenized_train_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f294b3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_datasets[0]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae1900",
   "metadata": {},
   "source": [
    "<h3>BCEWithLogitsLoss ()</h3><p> function which combines a Sigmoid layer and the BCELoss in one single class instead of having a plain Sigmoid followed by a BCELoss.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78e1e5-dd02-4af8-a314-bdf55c70ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the BERT model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_map.keys()), hidden_dropout_prob=0.1)\n",
    "model.resize_token_embeddings(len(tokenizer)) # need to resize due to new tokens added\n",
    "problem_type  = \"multi_label_classification\"\n",
    "model.config.problem_type = problem_type\n",
    "# 2. Define training arguments\n",
    "metric_name = 'f1'\n",
    "# model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"./snapshots/{model_name}-finetuned\",\n",
    "    evaluation_strategy=\"no\",  # No evaluation since there's no validation dataset\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# 3. Define a metric to compute during training\n",
    "metric = evaluate.load(metric_name)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return metric.compute(predictions=predictions.float(), references=labels, average=\"micro\")\n",
    "\n",
    "# 4. Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_train_datasets,\n",
    "    #eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "# 5. Train the model\n",
    "train_log = trainer.train() # resume from checkpoint if needed\n",
    "\n",
    "trainer.save_model(f\"./models/BERT_Multi-Label_classification\") # saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c383d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(f\"./models/BERT_Multi-Label_classification\", num_labels=len(label_map.keys()), hidden_dropout_prob=0.1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"./models/BERT_Multi-Label_classification\")\n",
    "model.resize_token_embeddings(len(tokenizer)) # need to resize due to new tokens added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf72b5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = tokenizer.model_max_length # maximum sequence length for tokenizing the input text\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b0b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we perform our evaluation on our test set using the fine-tuned model from earlier.\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0,return_all_scores=True)\n",
    "results = classifier(test_dataset['comment_text'], max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "dfResults = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf30be6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5\n",
       "0  0  0  0  0  0  0\n",
       "1  1  0  0  0  0  0\n",
       "2  1  0  0  0  0  1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedResults = dfResults.map(lambda x: np.int32(1) if x[\"score\"] > 0.5 else np.int32(0))\n",
    "cleanedResults = cleanedResults.to_numpy()\n",
    "f1 = f1_score(test_dataset['labels'], cleanedResults.tolist(), average='micro')  # or 'macro', 'weighted'\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
